{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, udf, split, window, from_unixtime, avg,  when, lit\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, LongType, TimestampType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "PREFIX = \"10m\"\n",
    "symbols_features = {\n",
    "    \"BP\": [\"volume\", \"volatility\", \"market_sentiment\", \"trading_activity\", \"price\"],\n",
    "    \"COP\": [\"volume\", \"volatility\", \"market_sentiment\", \"trading_activity\", \"price\"],\n",
    "    \"SHEL\": [\"volume\", \"volatility\", \"market_sentiment\", \"trading_activity\", \"price\"],\n",
    "    \"XOM\": [\"volume\", \"volatility\", \"market_sentiment\", \"trading_activity\", \"price\"],\n",
    "    \"ETHEREUM\": [\"bid\", \"ask\", \"spread_raw\", \"spread_table\", \"price\"],\n",
    "}\n",
    "\n",
    "if len(sys.argv) != 2:\n",
    "    raise ValueError(\"Please provide the TARGET_SYMBOL as a command-line argument.\")\n",
    "\n",
    "TARGET_SYMBOL = \"BP\"\n",
    "\n",
    "if TARGET_SYMBOL not in symbols_features:\n",
    "    raise ValueError(f\"TARGET_SYMBOL '{TARGET_SYMBOL}' is not defined in symbols_features.\")\n",
    "\n",
    "FEATURE_COLUMNS = symbols_features[TARGET_SYMBOL]\n",
    "NUM_FEATURES = len(FEATURE_COLUMNS)\n",
    "\n",
    "# Model and Checkpoint Paths with PREFIX\n",
    "MODEL_BASE_PATH = f\"./{PREFIX}/models/{TARGET_SYMBOL}\"\n",
    "CHECKPOINT_PATH_AGG = f\"./{PREFIX}/checkpoint/dir/{TARGET_SYMBOL}_agg\"\n",
    "CHECKPOINT_PATH_PRED = f\"./{PREFIX}/checkpoint/dir/{TARGET_SYMBOL}_pred\"\n",
    "\n",
    "os.makedirs(MODEL_BASE_PATH, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_PATH_AGG, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_PATH_PRED, exist_ok=True)\n",
    "\n",
    "CASSANDRA_KEYSPACE = \"stream_predictions\"\n",
    "CASSANDRA_TABLE = \"model_predictions_10m\"\n",
    "\n",
    "KAFKA_BROKERS = \"localhost:9092\"\n",
    "KAFKA_TOPIC = \"model-topic\"\n",
    "\n",
    "MAX_ITER = 50\n",
    "REG_PARAM = 0.01\n",
    "ELASTIC_NET_PARAM = 0.5\n",
    "\n",
    "HISTORICAL_MODEL_BASE_PATH = f\"./{PREFIX}/historical_models/{TARGET_SYMBOL}\"\n",
    "os.makedirs(HISTORICAL_MODEL_BASE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMN = \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_port_offset = {\n",
    "    \"ETHEREUM\": 0,\n",
    "    \"SHEL\": 1,\n",
    "    \"BP\": 2,\n",
    "    \"COP\": 3,\n",
    "    \"XOM\": 4\n",
    "}\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(f\"ContinuousTrainingLinearRegression_{TARGET_SYMBOL}\") \\\n",
    "    .config(\"spark.jars.packages\",\n",
    "            \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,\"\n",
    "            \"com.datastax.spark:spark-cassandra-connector_2.12:3.5.0\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"localhost\") \\\n",
    "    .config(\"spark.ui.port\", str(4050 + spark_port_offset[TARGET_SYMBOL])) \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    latest_model_path = os.path.join(MODEL_BASE_PATH, f\"latest_model.txt\")\n",
    "    if os.path.exists(latest_model_path):\n",
    "        try:\n",
    "            with open(latest_model_path, \"r\") as f:\n",
    "                model_path = f.read().strip()\n",
    "            model = LinearRegressionModel.load(model_path)\n",
    "            print(f\"[{TARGET_SYMBOL}] Loaded model from {model_path}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"[{TARGET_SYMBOL}] Error loading model: {e}\")\n",
    "    return None\n",
    "\n",
    "def save_model(model):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = os.path.join(MODEL_BASE_PATH, f\"model_{timestamp}\")\n",
    "    model.write().overwrite().save(model_path)\n",
    "\n",
    "    latest_model_path = os.path.join(MODEL_BASE_PATH, \"latest_model.txt\")\n",
    "    with open(latest_model_path, \"w\") as f:\n",
    "        f.write(model_path)\n",
    "\n",
    "def load_historical_model():\n",
    "    \"\"\"\n",
    "    Load the historical model from disk\n",
    "    \"\"\"\n",
    "    latest_model_path = os.path.join(HISTORICAL_MODEL_BASE_PATH, f\"latest_model.txt\")\n",
    "    if os.path.exists(latest_model_path):\n",
    "        try:\n",
    "            with open(latest_model_path, \"r\") as f:\n",
    "                model_path = f.read().strip()\n",
    "            model = LinearRegressionModel.load(model_path)\n",
    "            print(f\"[{TARGET_SYMBOL}] Loaded historical model from {model_path}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"[{TARGET_SYMBOL}] Error loading historical model: {e}\")\n",
    "    return None\n",
    "\n",
    "def save_historical_model(model):\n",
    "    \"\"\"\n",
    "    Save the historical model to disk\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = os.path.join(HISTORICAL_MODEL_BASE_PATH, f\"model_{timestamp}\")\n",
    "    model.write().overwrite().save(model_path)\n",
    "\n",
    "    latest_model_path = os.path.join(HISTORICAL_MODEL_BASE_PATH, \"latest_model.txt\")\n",
    "    with open(latest_model_path, \"w\") as f:\n",
    "        f.write(model_path)\n",
    "    print(f\"[{TARGET_SYMBOL}] Saved historical model to {model_path}\")\n",
    "\n",
    "def update_model(batch_df: DataFrame, batch_id: int):\n",
    "    global lr_model\n",
    "\n",
    "    if batch_df.rdd.isEmpty():\n",
    "        print(f\"[{TARGET_SYMBOL}] Batch {batch_id} is empty. Skipping update.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        lr = LinearRegression(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            maxIter=MAX_ITER,\n",
    "            regParam=REG_PARAM,\n",
    "            elasticNetParam=ELASTIC_NET_PARAM\n",
    "        )\n",
    "        new_model = lr.fit(batch_df)\n",
    "        lr_model = new_model\n",
    "\n",
    "        print(f\"[{TARGET_SYMBOL}] Updated model with batch {batch_id}\")\n",
    "        print(f\"[{TARGET_SYMBOL}] Coefficients: {lr_model.coefficients}\")\n",
    "        print(f\"[{TARGET_SYMBOL}] Intercept: {lr_model.intercept}\")\n",
    "\n",
    "        save_model(lr_model)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{TARGET_SYMBOL}] Error in batch {batch_id}: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from typing import Tuple, Dict\n",
    "SELECTED_MODEL_TYPE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_historical_models(historical_features, test_size: float = 0.2) -> Tuple[object, str, Dict]:\n",
    "    \"\"\"\n",
    "    Trains multiple models on historical data and evaluates their performance.\n",
    "    Returns the best model, its type, and evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Split data into training and test sets\n",
    "    train_data, test_data = historical_features.randomSplit([1 - test_size, test_size], seed=42)\n",
    "    \n",
    "    # Initialize models with their parameters\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            maxIter=MAX_ITER,\n",
    "            regParam=REG_PARAM,\n",
    "            elasticNetParam=ELASTIC_NET_PARAM\n",
    "        ),\n",
    "        'RandomForest': RandomForestRegressor(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            numTrees=100,\n",
    "            maxDepth=10,\n",
    "            seed=42\n",
    "        ),\n",
    "        'GradientBoosting': GBTRegressor(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            maxIter=100,\n",
    "            maxDepth=5\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    model_metrics = {}\n",
    "    best_rmse = float('inf')\n",
    "    best_model = None\n",
    "    best_model_type = None\n",
    "    \n",
    "    print(f\"[{TARGET_SYMBOL}] Training and evaluating models...\")\n",
    "    \n",
    "    for model_type, model in models.items():\n",
    "        try:\n",
    "            # Train model\n",
    "            print(f\"[{TARGET_SYMBOL}] Training {model_type}...\")\n",
    "            trained_model = model.fit(train_data)\n",
    "            \n",
    "            # Make predictions on test data\n",
    "            predictions = trained_model.transform(test_data)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            \n",
    "            # Calculate additional metrics\n",
    "            evaluator.setMetricName(\"mae\")\n",
    "            mae = evaluator.evaluate(predictions)\n",
    "            evaluator.setMetricName(\"r2\")\n",
    "            r2 = evaluator.evaluate(predictions)\n",
    "            \n",
    "            model_metrics[model_type] = {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'r2': r2\n",
    "            }\n",
    "            \n",
    "            print(f\"[{TARGET_SYMBOL}] {model_type} metrics:\")\n",
    "            print(f\"    RMSE: {rmse:.4f}\")\n",
    "            print(f\"    MAE: {mae:.4f}\")\n",
    "            print(f\"    R2: {r2:.4f}\")\n",
    "            \n",
    "            # Update best model if current model performs better\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_model = trained_model\n",
    "                best_model_type = model_type\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"[{TARGET_SYMBOL}] Error training {model_type}: {str(e)}\")\n",
    "            model_metrics[model_type] = None\n",
    "    \n",
    "    if best_model is None:\n",
    "        raise ValueError(\"No models were successfully trained\")\n",
    "    \n",
    "    # Update global selected model type\n",
    "    global SELECTED_MODEL_TYPE\n",
    "    SELECTED_MODEL_TYPE = best_model_type\n",
    "    \n",
    "    # Save the best model\n",
    "    save_historical_model(best_model)\n",
    "    \n",
    "    print(f\"[{TARGET_SYMBOL}] Best performing model: {best_model_type}\")\n",
    "    return best_model, best_model_type, model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_historical_data():\n",
    "    \"\"\"\n",
    "    Loads historical data from Cassandra and trains initial model with debug info\n",
    "    \"\"\"\n",
    "    print(f\"[{TARGET_SYMBOL}] Loading historical data from Cassandra...\")\n",
    "    \n",
    "    # Load historical data from Cassandra\n",
    "    historical_df = spark.read \\\n",
    "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "        .options(table=CASSANDRA_TABLE, keyspace=CASSANDRA_KEYSPACE) \\\n",
    "        .load() \\\n",
    "        .filter(col(\"symbol\") == TARGET_SYMBOL)\n",
    "\n",
    "    # Debug print\n",
    "    print(f\"[{TARGET_SYMBOL}] Initial schema:\")\n",
    "    historical_df.printSchema()\n",
    "    print(f\"[{TARGET_SYMBOL}] Initial count: {historical_df.count()}\")\n",
    "\n",
    "    if historical_df.rdd.isEmpty():\n",
    "        raise ValueError(f\"No historical data found for symbol {TARGET_SYMBOL}\")\n",
    "\n",
    "    # Parse input_data JSON to get features\n",
    "    for feature in FEATURE_COLUMNS:\n",
    "        historical_df = historical_df.withColumn(\n",
    "            feature,\n",
    "            F.get_json_object(col(\"input_data\"), f\"$.{feature}\").cast(\"double\")\n",
    "        )\n",
    "    \n",
    "    # Debug print after feature extraction\n",
    "    print(f\"[{TARGET_SYMBOL}] Schema after feature extraction:\")\n",
    "    historical_df.printSchema()\n",
    "    print(f\"[{TARGET_SYMBOL}] Sample data after feature extraction:\")\n",
    "    historical_df.select(\"symbol\", *FEATURE_COLUMNS, \"label\").show(5)\n",
    "\n",
    "    # Add event_time column if not exists\n",
    "    if \"event_time\" not in historical_df.columns:\n",
    "        historical_df = historical_df.withColumn(\n",
    "            \"event_time\",\n",
    "            (col(\"timestamp\") / 1000).cast(TimestampType())\n",
    "        )\n",
    "\n",
    "    # Group by 10-minute windows\n",
    "    historical_windowed = historical_df \\\n",
    "        .groupBy(\n",
    "            window(col(\"event_time\"), \"10 minutes\"),\n",
    "            col(\"symbol\")\n",
    "        ) \\\n",
    "        .agg(\n",
    "            *[\n",
    "                F.avg(col(feature)).alias(f\"avg_{feature}\")\n",
    "                for feature in FEATURE_COLUMNS\n",
    "            ],\n",
    "            F.avg(col(\"label\")).alias(\"label\")\n",
    "        )\n",
    "\n",
    "    # Debug print after windowing\n",
    "    print(f\"[{TARGET_SYMBOL}] Schema after windowing:\")\n",
    "    historical_windowed.printSchema()\n",
    "    print(f\"[{TARGET_SYMBOL}] Sample data after windowing:\")\n",
    "    historical_windowed.show(5)\n",
    "\n",
    "    # Check for null values\n",
    "    for feature in [f\"avg_{feature}\" for feature in FEATURE_COLUMNS] + [\"label\"]:\n",
    "        null_count = historical_windowed.filter(col(feature).isNull()).count()\n",
    "        if null_count > 0:\n",
    "            print(f\"[{TARGET_SYMBOL}] WARNING: Found {null_count} null values in {feature}\")\n",
    "\n",
    "    # Prepare features\n",
    "    assembler_historical = VectorAssembler(\n",
    "        inputCols=[f\"avg_{feature}\" for feature in FEATURE_COLUMNS],\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        historical_features = assembler_historical.transform(historical_windowed)\n",
    "        \n",
    "        # Debug print assembled features\n",
    "        print(f\"[{TARGET_SYMBOL}] Schema after feature assembly:\")\n",
    "        historical_features.printSchema()\n",
    "        print(f\"[{TARGET_SYMBOL}] Sample data after feature assembly:\")\n",
    "        historical_features.select(\"features\", \"label\").show(5, truncate=False)\n",
    "        \n",
    "        # Check for problematic data\n",
    "        invalid_count = historical_features.filter(\n",
    "            col(\"features\").isNull() | \n",
    "            col(\"label\").isNull() |\n",
    "            F.isnan(\"label\")\n",
    "        ).count()\n",
    "        \n",
    "        if invalid_count > 0:\n",
    "            print(f\"[{TARGET_SYMBOL}] WARNING: Found {invalid_count} rows with null/NaN features or labels\")\n",
    "            \n",
    "            # Remove problematic rows\n",
    "            historical_features = historical_features.filter(\n",
    "                col(\"features\").isNotNull() & \n",
    "                col(\"label\").isNotNull() &\n",
    "                ~F.isnan(\"label\")\n",
    "            )\n",
    "            print(f\"[{TARGET_SYMBOL}] Cleaned data count: {historical_features.count()}\")\n",
    "            \n",
    "        best_model, model_type, metrics = train_and_evaluate_historical_models(historical_features)\n",
    "        \n",
    "        print(f\"[{TARGET_SYMBOL}] Selected model type: {SELECTED_MODEL_TYPE}\")\n",
    "        print(f\"[{TARGET_SYMBOL}] Model evaluation metrics:\")\n",
    "        for model_type, model_metrics in metrics.items():\n",
    "            if model_metrics:\n",
    "                print(f\"\\n{model_type}:\")\n",
    "                for metric, value in model_metrics.items():\n",
    "                    print(f\"    {metric}: {value:.4f}\")\n",
    "        \n",
    "        return best_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[{TARGET_SYMBOL}] Error during model training and evaluation: {str(e)}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1726:====>        (68 + 2) / 200][Stage 1728:>               (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Start label updater stream\n",
    "def update_labels(batch_df: DataFrame, batch_id: int):\n",
    "    if batch_df.rdd.isEmpty():\n",
    "        return\n",
    "\n",
    "    # Calculate 10-minute average prices and select window bounds\n",
    "    avg_prices = batch_df.groupBy(\n",
    "        window(col(\"event_time\"), \"10 minutes\")\n",
    "    ).agg(\n",
    "        avg(\"label\").alias(\"actual_price\")\n",
    "    ).select(\n",
    "        col(\"window.start\").alias(\"window_start\"),\n",
    "        col(\"window.end\").alias(\"window_end\"),\n",
    "        col(\"actual_price\")\n",
    "    )\n",
    "\n",
    "    # For each window, update records in Cassandra\n",
    "    for row in avg_prices.collect():\n",
    "        window_start = row['window_start']\n",
    "        window_end = row['window_end']\n",
    "        actual_price = row['actual_price']\n",
    "        \n",
    "        # Read matching records\n",
    "        matching_records = spark.read \\\n",
    "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "            .options(table=CASSANDRA_TABLE, keyspace=CASSANDRA_KEYSPACE) \\\n",
    "            .load() \\\n",
    "            .filter(\n",
    "                (col(\"symbol\") == TARGET_SYMBOL) &\n",
    "                (col(\"event_time\") >= window_start) &\n",
    "                (col(\"event_time\") < window_end)\n",
    "            )\n",
    "\n",
    "        # Update records with actual price\n",
    "        if not matching_records.rdd.isEmpty():\n",
    "            matching_records \\\n",
    "                .withColumn(\"label\", F.lit(actual_price)) \\\n",
    "                .write \\\n",
    "                .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "                .mode(\"append\") \\\n",
    "                .options(table=CASSANDRA_TABLE, keyspace=CASSANDRA_KEYSPACE) \\\n",
    "                .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_model = train_on_historical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    }
   ],
   "source": [
    "print(SELECTED_MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_incoming(batch_df: DataFrame, batch_id: int):\n",
    "    global historical_model, lr_model\n",
    "    \n",
    "    if batch_df.rdd.isEmpty():\n",
    "        print(f\"[{TARGET_SYMBOL}] Predictor batch {batch_id} empty\")\n",
    "        return\n",
    "\n",
    "    if historical_model is None:\n",
    "        historical_model = load_historical_model()\n",
    "    if lr_model is None:\n",
    "        lr_model = load_model()\n",
    "\n",
    "    if lr_model is None or historical_model is None:\n",
    "        print(f\"[{TARGET_SYMBOL}] One or both models not available\")\n",
    "        return\n",
    "\n",
    "    # Get predictions from both models\n",
    "    streaming_predictions = lr_model.transform(batch_df)\n",
    "    historical_predictions = historical_model.transform(batch_df)\n",
    "\n",
    "    # Combine predictions\n",
    "    predictions = streaming_predictions.select(\n",
    "        col(\"symbol\"),\n",
    "        col(\"timestamp\"),\n",
    "        col(\"event_time\"),\n",
    "        col(\"features\"),\n",
    "        col(\"label\"),\n",
    "        col(\"prediction\").alias(\"prediction\"),\n",
    "        historical_predictions.prediction.alias(\"prediction_historical\")\n",
    "    )\n",
    "\n",
    "    @udf(StringType())\n",
    "    def features_to_json(features):\n",
    "        return json.dumps({\n",
    "            f: float(value) for f, value in zip(FEATURE_COLUMNS, features)\n",
    "        })\n",
    "\n",
    "    predictions_to_save = predictions.withColumn(\n",
    "        \"input_data\", \n",
    "        features_to_json(col(\"features\"))\n",
    "    ).withColumn(\n",
    "        \"label\",\n",
    "        F.lit(None).cast(DoubleType())\n",
    "    )\n",
    "\n",
    "    predictions_to_save.select(\n",
    "        col(\"symbol\"),\n",
    "        col(\"timestamp\"),\n",
    "        col(\"event_time\"),\n",
    "        col(\"input_data\"),\n",
    "        col(\"prediction\"),\n",
    "        col(\"prediction_historical\"),\n",
    "        col(\"label\")\n",
    "    ).write \\\n",
    "     .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "     .mode(\"append\") \\\n",
    "     .options(table=CASSANDRA_TABLE, keyspace=CASSANDRA_KEYSPACE) \\\n",
    "     .save()\n",
    "\n",
    "    print(f\"[{TARGET_SYMBOL}] Completed predictions for batch {batch_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"symbol\", StringType()) \\\n",
    "    .add(\"timestamp\", LongType()) \\\n",
    "    .add(\"source\", StringType()) \\\n",
    "    .add(\"data_type\", StringType()) \\\n",
    "    .add(\"bid\", DoubleType()) \\\n",
    "    .add(\"ask\", DoubleType()) \\\n",
    "    .add(\"price\", DoubleType()) \\\n",
    "    .add(\"volume\", DoubleType()) \\\n",
    "    .add(\"spread_raw\", DoubleType()) \\\n",
    "    .add(\"spread_table\", DoubleType()) \\\n",
    "    .add(\"volatility\", DoubleType()) \\\n",
    "    .add(\"market_sentiment\", DoubleType()) \\\n",
    "    .add(\"trading_activity\", DoubleType())\n",
    "\n",
    "df_kafka = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BROKERS) \\\n",
    "    .option(\"subscribe\", KAFKA_TOPIC) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .option(\"kafkaConsumer.pollTimeoutMs\", 180000) \\\n",
    "    .load()\n",
    "\n",
    "parsed_df = df_kafka.selectExpr(\"CAST(value AS STRING) as json\") \\\n",
    "    .select(from_json(col(\"json\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "filtered_df = parsed_df.filter(col(\"symbol\") == TARGET_SYMBOL)\n",
    "\n",
    "LABEL_COLUMN = \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the 'price' for Ethereum if it's set to -1 by computing the average of 'bid' and 'ask'\n",
    "if TARGET_SYMBOL == \"ETHEREUM\":\n",
    "    # Create a corrected 'price' column\n",
    "    corrected_price = when(col(\"price\") == -1, (col(\"bid\") + col(\"ask\")) / 2).otherwise(col(\"price\"))\n",
    "    \n",
    "    # Apply the corrected 'price' to both 'price' feature and 'label'\n",
    "    processed_df = filtered_df.withColumn(\n",
    "        \"price_corrected\",\n",
    "        corrected_price.cast(\"double\")\n",
    "    ).select(\n",
    "        col(\"symbol\").alias(\"symbol\"),\n",
    "        *[col(feature).cast(\"double\").alias(f\"{feature}\") for feature in FEATURE_COLUMNS if feature != \"price\"],\n",
    "        col(\"price_corrected\").alias(\"price\"),  # Updated 'price' for features\n",
    "        col(\"price_corrected\").alias(\"label\"),  # Updated 'label'\n",
    "        col(\"timestamp\").cast(\"long\").alias(\"timestamp\")  # Include timestamp for Cassandra or other sinks\n",
    "    )\n",
    "else:\n",
    "    # For other symbols, no correction needed\n",
    "    processed_df = filtered_df.select(\n",
    "        col(\"symbol\").alias(\"symbol\"),\n",
    "        *[col(feature).cast(\"double\").alias(f\"{feature}\") for feature in FEATURE_COLUMNS],\n",
    "        col(LABEL_COLUMN).cast(\"double\").alias(\"label\"),  # Use the original 'price' as label\n",
    "        col(\"timestamp\").cast(\"long\").alias(\"timestamp\")  # Include timestamp for Cassandra or other sinks\n",
    "    )\n",
    "\n",
    "processed_df = processed_df.withColumn(\n",
    "    \"event_time\",\n",
    "    (col(\"timestamp\") / 1000).cast(TimestampType())\n",
    ")\n",
    "\n",
    "# Modified to use 10-minute windows\n",
    "windowed_df = processed_df \\\n",
    "    .withWatermark(\"event_time\", \"20 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(col(\"event_time\"), \"10 minutes\"),\n",
    "        col(\"symbol\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        *[\n",
    "            F.avg(col(feature)).alias(f\"avg_{feature}\") \n",
    "            for feature in FEATURE_COLUMNS\n",
    "        ],\n",
    "        F.avg(col(\"label\")).alias(\"label\")  # Use 10-minute average as label\n",
    "    )\n",
    "\n",
    "aggregated_feature_columns = [f\"avg_{feature}\" for feature in FEATURE_COLUMNS]\n",
    "\n",
    "assembler_agg = VectorAssembler(\n",
    "    inputCols=aggregated_feature_columns,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "windowed_features_df = assembler_agg.transform(windowed_df).select(\n",
    "    \"symbol\",\n",
    "    \"features\",\n",
    "    \"label\",\n",
    "    col(\"window.start\").alias(\"window_start\"),\n",
    "    col(\"window.end\").alias(\"window_end\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start aggregator stream with 10-minute trigger\n",
    "query_agg = windowed_features_df.writeStream \\\n",
    "    .foreachBatch(update_model) \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_PATH_AGG) \\\n",
    "    .trigger(processingTime='10 minutes') \\\n",
    "    .start()\n",
    "\n",
    "print(f\"[{TARGET_SYMBOL}] Started aggregator query\")\n",
    "\n",
    "# Predictor stream setup\n",
    "assembler_pred = VectorAssembler(\n",
    "    inputCols=FEATURE_COLUMNS,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Process each record immediately for prediction\n",
    "processed_df_for_pred = assembler_pred.transform(\n",
    "    processed_df.select(\"symbol\", *FEATURE_COLUMNS, \"label\", \"timestamp\", \"event_time\")\n",
    ").select(\n",
    "    \"symbol\",\n",
    "    \"features\",\n",
    "    \"label\",\n",
    "    \"timestamp\",\n",
    "    \"event_time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1723:==>                                                    (1 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BP] Started predictor query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1724:>               (0 + 1) / 1][Stage 1726:>             (1 + 1) / 200]\r"
     ]
    }
   ],
   "source": [
    "# Start predictor stream with minimal trigger interval\n",
    "query_pred = processed_df_for_pred.writeStream \\\n",
    "    .foreachBatch(predict_incoming) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_PATH_PRED) \\\n",
    "    .trigger(processingTime='1 second') \\\n",
    "    .start()\n",
    "\n",
    "print(f\"[{TARGET_SYMBOL}] Started predictor query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start label updater stream\n",
    "query_labels = processed_df.writeStream \\\n",
    "    .foreachBatch(update_labels) \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .trigger(processingTime='10 minutes') \\\n",
    "    .start()\n",
    "\n",
    "spark.streams.awaitAnyTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
